<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NIDRA</title>
    <link rel="stylesheet" href="style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
</head>
<body>
    <nav class="sidebar">
        <br><br><br>
        <ul>
            <li><a href="#installation">Installation</a></li>
            <li><a href="#preparing-data">Preparing your data</a></li>
            <li><a href="#gui-walkthrough">GUI guide</a></li>
            <li><a href="#model-performance">Model validation</a></li>
            <li><a href="#understanding-results">Understanding results</a></li>
            <li><a href="#python-package">Python endpoints</a></li>
            <li><a href="#how-to-cite">How to cite</a></li>
            <li><a href="#faq">FAQ & troubleshooting</a></li>
            <li><a href="#contact">Contact</a></li>
        </ul>
    </nav>
    <main class="content">
        <section id="introduction">
            <div class="intro-container">
                <div class="intro-logo">
                    <img src="logo.png" alt="NIDRA Logo" class="logo">
                </div>
                <div>
                    <h1>NIDRA v0.1.1 - super simple sleep scoring</h1>
                    <a href="https://github.com/paulzerr/nidra" class="intro-link">https://github.com/paulzerr/nidra</a>
                    <p>An easy way to use powerful machine learning models to autoscore sleep recordings with excellent accuracy. No programming required, but Python endpoints are available. NIDRA can accurately score recordings from 2-channel EEG wearables such as ZMax (using ez6 and ez6moe models), as well as full PSG recordings (using U-Sleep 2.0 via sleepyland).</p>

                    <p><h2><strong>Download <a href="https://github.com/paulzerr/nidra/releases/latest/download/NIDRA.exe">NIDRA for Windows 10/11</a></strong></h1></p>
                <p></p>
                <br>
                </div>
            </div>
        </section>

        <section id="installation">
            <h2>Installation</h2>
            <h3>Option 1: Standalone installer</h3>
            <p>The easiest way to use NIDRA on Windows is to <a href="https://github.com/paulzerr/nidra/releases/latest/download/NIDRA.exe">download</a> the portable self-extracting archive which requires no installation.</p>
<p><strong>Note:</strong> due to the restrictive environment of Windows, you may see a "Search on app store" popup window. Click "No". You may also see the blue Smartscreen warning. In that case click "More info" and then "run anyway". Should this fail, try installing via pip (see below).</p>

            <h3>Option 2: Install with pip</h3>
            <p>It is highly recommended to create a clean virtual environment to install NIDRA. This prevents conflicts with other packages. Python 3.10 recommended.</p>
            <p><strong>Windows:</strong></p>
            <pre><code>python -m venv nidra-env
nidra-env\Scripts\activate
pip install nidra</code></pre>
            <p><strong>Mac/Linux:</strong></p>
            <pre><code>python -m venv nidra-env
source nidra-env/bin/activate
pip install nidra</code></pre>
            <p><strong>Or install using Conda (Windows/Mac/Linux):</strong></p>
            First install e.g., <a href="https://www.anaconda.com/download/success">Miniconda</a>.</p>
            <pre><code>conda create -n nidra-env
conda activate nidra-env
pip install nidra</code></pre>
            <p><strong>Launch the graphical interface:</strong></p>
            <pre><code>nidra</code></pre>
            <p><strong>Note:</strong> If you installed via pip, the first time you run NIDRA, the necessary model files will be automatically downloaded from <a href="https://huggingface.co/pzerr/NIDRA_models/">https://huggingface.co/pzerr/NIDRA_models/</a> (~152MB). </p>
            <h3>Option 3: Install from source</h3>
            <pre><code>git clone https://github.com/paulzerr/nidra.git
cd NIDRA
pip install .</code></pre>
        </section>

        <section id="gui-guide">
            <h2>Graphical user interface (GUI)</h2>
            <p>The GUI provides an intuitive, point-and-click option to score sleep recordings. The easiest way to launch the GUI is by downloading and starting the self-extracting archive (see above). Or, if you installed NIDRA as a Python package, you can launch it by opening your terminal or cmd and running the command: <code>nidra</code></p>
            <img src="gui.png" alt="Screenshot of the NIDRA GUI" style="width: 90%; display: block; margin: 20px 0;">
            <p><b>Fig.1</b> - Screenshot of the GUI. </p>

            <h2>GUI Walkthrough</h2>
            <h3>Step 1: Start the NIDRA GUI</h3>
            <p>For installation see top of this page. If installed via the standalone version, go to the directory where you extracted the files and double-click <code>NIDRA.exe</code>. </p>
            <p><strong>Note:</strong> due to the restrictive environment of Windows, you may see a "Search on app store" popup window. Click "No". You may also see the blue Smartscreen warning. In that case click "More info" and then "run anyway". Should this fail, try installing via pip (see installation section).</p>
            <p>Alternatively, if you installed NIDRA as a Python package, open your terminal (On Windows: press CTRL+R, type in cmd, press Enter) and type <code>nidra</code>, then press Enter. The main application window will appear.</p>

            <h3>Step 2: Set input and output paths</h3>
            <p>Tell NIDRA where your data is located and where the results should go.</p>
            <ul>
                <li><strong>Input Directory:</strong> Click "Browse files...". Navigate to and select the folder that contains your sleep recording file(s). For batch processing, this would be your main project folder containing subdirectories for each recording. Please see "Preparing your data" section above for details.</li>
                <li><strong>Output Directory:</strong> Specify the folder where NIDRA will save the scoring results. If you leave this blank, NIDRA will automatically create a new folder named <code>autoscorer_output</code> inside your input directory. </li>
            </ul>
            <h3>Step 3: Configure scoring options</h3>
            <p>Specify how your data is organized. Please see the "Input file options" section below for details.</p>
            <h3>Step 4: Select recording type and model</h3>
            <ul>
                <li><strong>Data Source:</strong> Select the type of recording you have. Choose "EEG wearable" for 2-channel wearable data (e.g., ZMax) or "PSG" for standard polysomnography data.</li>
                <li><strong>Model:</strong> The available models will change based on your recording type. For forehead EEG, <code>ez6moe</code> is recommended for its high accuracy. This model will take approximately 30 seconds to score one night. Alternatively, use <code>ez6</code>, which runs in about 5 seconds, but has slightly lower accuracy. For PSG, <code>u-sleep-nsrr-2024</code> is the standard choice. This model uses all available EEG and EOG channels and will run one scoring process for each possible combination of single EEG and EOG channels, and then take a majority vote from each scoring process. If there are no EOG channels available, NIDRA will automatically use the EEG-only <code>u-sleep-nsrr-2024_eeg</code> model.</li>
            </ul>
            <h3>Step 5: Run the analysis</h3>
            <p>Sleep stage output is always generated. You can choose whether to additionally generate classifier probability output, graphs, sleep statistics using the checkboxes. Click the <strong>"Begin Autoscoring"</strong> button to begin. You can monitor the real-time progress in the console panel on the right. This log will show which files are being processed and report any warnings or errors.</p>
        </section>


        <section id="preparing-data">
            <h2>Preparing your data</h2>
            <ul>
                <li>In general, NIDRA expects to find each recording (.edf) in its own subfolder. However, you can also input a text file that contains the file locations.</li>
                <li>If you use standard channel labels (e.g., 'EEG Fpz-Cz', 'EOG left', 'Fp1', 'O2-M1') in your PSG recordings, NIDRA uses these to identify channel types. If no clear channel names are provided, all channels are used and assumed to be EEG.</li>
            </ul>

            <h3 id="scoring-options">Input file options</h3>
            <ul>
                <li><strong>Score single recording:</strong> Score a single recording. Specify the .edf file, or the folder containing the edf file(s). For ZMax file pairs, you can specify either the left or right channel edf.</li>
                <li><strong>Score all recordings (in subfolders):</strong> Score multiple recordings. NIDRA will look for subfolders within your selected input folder and process each one as a separate recording.</li>
                <li><strong>Score all recordings (paths in .txt file):</strong> Specify a <code>.txt</code> file as input, which contains one absolute path to a single edf file per line to tell NIDRA which recordings to score. If you choose this option, file organization is irrelevant.</li>
            </ul>
<p><strong>Structure for Forehead EEG (e.g., ZMax):</strong></p>
            <p>For ZMax EEG data, the left and right channel files must be in the same directory. These are typically named <code>EEG_L.edf</code> and <code>EEG_R.edf</code>. However, you can also supply ZMax recordings (or data from any forehead EEG device) with both EEG channels in the same .edf file. NIDRA will automatically detect this.</p>
            <pre>
forehead_study/
├── subject_01/
|   ├── EEG_L.edf
|   └── EEG_R.edf
├── subject_02/
|   ├── night01_L.edf
|   └── night01_R.edf
</pre>
            <p><strong>Structure for PSG:</strong></p>
            <p>Similarly, for PSG data, each EDF file should be in its own directory.</p>
            <pre>
psg_study/
├── subject_02/
|   └── night_recording_1.edf
├── subject_03/
|   └── night_recording_2.edf
└── subject_04/
    └── another_night.edf
</pre>

<p><strong>Selecting channels</strong></p>
            <p>You can optionally specify which channels to use for scoring. NIDRA will automatically detect EEG and EOG channels based on their names, and ignore other channels as they are not used by any of the models. </p>



        </section>


        <section id="model-performance">
            <h2>Model validation and performance</h2>
            <p>The models included in NIDRA have been rigorously validated against manually scored data from human experts. Below is a summary of their performance.</p>
            <h3>ez6 and ez6moe for forehead EEG</h3>
            <p><code>ez6moe</code> is recommended for its high accuracy. This model will take approximately 30 seconds to score one night. Alternatively, use <code>ez6</code>, which runs in about 5 seconds, but has slightly lower accuracy. This is mostly useful for testing purposes or real-time applications.
                The confusion matrix below shows the <code>ez6moe</code> model's predictions (y-axis) versus the expert labels (x-axis). The diagonal represents correct classifications. The model shows high agreement with the expert scorer, particularly for Wake, N2, and REM sleep. For further details, please see ezscore-f paper in the Attributions section below.</p>
            <img src="matrix.png" alt="Confusion matrix of the ez6moe model" style="width: 60%; max-width: 600px; display: block; margin: 20px 0;">
            <p><b>Fig.2</b> - Confusion matrix (vs. manually scored PSG) of the artefact-aware ez6moe model.</p>
            <p>Key performance metrics, such as accuracy and Cohen's Kappa (a measure of inter-rater agreement), are comparable to the agreement levels seen between different human experts. For full details, please refer to the original publication.</p>
            <h3>U-Sleep for PSG</h3>
            <p>The U-Sleep model is a well-established, state-of-the-art algorithm for PSG sleep scoring. The version used in NIDRA (<code>u-sleep-nsrr-2024</code>) is a robust implementation trained on a large dataset. It demonstrates high performance across diverse populations and recording conditions. For detailed performance metrics, please see the original U-Sleep and SLEEPYLAND publications linked in the Attribution section.</p>
        </section>

        <section id="understanding-results">
            <h2>Understanding your results</h2>
            <table class="minimal">
                <thead>
                    <tr><th style="text-align:left">Output file</th><th style="text-align:left">Description</th></tr>
                </thead>
                <tbody>
                    <tr><td><code>..._hypnogram.csv</code></td><td>A CSV with one integer per 30 s epoch (sleep stage code).</td></tr>
                    <tr><td><code>..._probabilities.csv</code></td><td>Classifier probabilities per epoch; one column per stage (Wake, N1, N2, N3, REM, Artifact).</td></tr>
                    <tr><td><code>..._dashboard.png</code></td><td>Plot with hypnogram, time-frequency spectrogram, and hypnodensity.</td></tr>
                    <tr><td><code>..._sleep_statistics.csv</code></td><td>Summary metrics (TST, efficiency, time in each stage, etc.).</td></tr>
                </tbody>
            </table>

            <table class="minimal">
                <thead>
                    <tr><th style="text-align:left">Sleep stage</th><th style="text-align:left">Code</th></tr>
                </thead>

                <p></p><br>
                <tbody>
                    <tr><td>Wake</td><td>0</td></tr>
                    <tr><td>N1</td><td>1</td></tr>
                    <tr><td>N2</td><td>2</td></tr>
                    <tr><td>N3</td><td>3</td></tr>
                    <tr><td>REM</td><td>5</td></tr>
                    <tr><td>Artifact</td><td>6</td></tr>
                </tbody>
            </table>
        </section>


        <section id="python-package">





            <h2>Python endpoints</h2>

<h3>Example 1: Scoring a single PSG recording (minimal example)</h3>
            <pre>
import NIDRA

scorer = NIDRA.scorer(
    type = 'psg',
    input = '/path/to/edf/or/folder/'
)

scorer.score()
</pre>

            <h3>Example 2: Scoring a single wearable-EEG recording File (specifying optional parameters)</h3>
            <pre>
import NIDRA

# initialize the scorer instance
scorer = NIDRA.scorer(
    type = 'forehead',
    input = '/path/to/recording/',
    output = '/path/to/output/folder/',
    model = 'ez6moe',
    channels = ['eegl','eegr'],
    hypnogram = True,
    probabilities = True,
    plot = True,
)

# run the scoring and get outputs as array
hypnogram, probabilities = scorer.score()

</pre>


            <h3>Example 3: Scoring multiple PSG recordings</h3>
            <p>For batch processing, NIDRA provides a convenient <code>batch_scorer</code>. This function automatically discovers all valid recordings in the subdirectories of your input path, mirroring the behavior of the GUI. This is the recommended way to process a full study. Please see the <a href="#preparing-data">Preparing Your Data</a> section for details on how to structure your study directory.</p>

            <pre>
import NIDRA

batch = NIDRA.batch_scorer(
    type='psg',
    input_dir='/path/to/folder/with/subfolders/', # or: .txt file with edf paths
    output='/path/to/output/folder/',
    probabilities=True,
    plot=True
)

batch.score()
</pre>
            <h3>Example 4: Scoring in-memory data (e.g. real-time application)</h3>
            <p>You can also score data that you already have in memory as an array. This is useful for real-time applications or custom data loading pipelines. When scoring PSG data from an array, you must provide the sampling frequency (<code>sfreq</code>). Providing channel names is recommended but optional; if not provided, they will be auto-generated. All channels are then assumed to contain EEG data. By default, no output files are generated, but this can be enabled if desired.</p>
            <pre>
# Create some dummy PSG data
import numpy as np
sfreq = 256
channels = ['F3-A2', 'C4-A1', 'O2-A1', 'EOG-L']
n_samples = sfreq * 60 * 60  # 1 hour of data
dummy_data = np.random.randn(len(channels), n_samples)

import NIDRA

scorer = NIDRA.scorer(
    type='psg',
    data=dummy_data,
    sfreq=sfreq,
    channels=channels
)
hypnogram, probabilities = scorer.score()

</pre>







<br>
<h3>Reference</h3>

<p>Single user-facing entry point <code>NIDRA.scorer(...)</code>. The concrete scorer is selected by <code>scorer_type</code>. Then call <code>.score()</code> to run inference. This unified reference clarifies which parameters are required, optional, and their defaults across PSG/Forehead and file/array scenarios.</p>

<h4>Entrypoint</h4>
<pre><code>NIDRA.scorer(scorer_type: str, **kwargs) -> Scorer
Scorer.score(plot: bool = False) -> tuple[numpy.ndarray, numpy.ndarray]</code></pre>

<h4>Returns</h4>
<ul>
  <li><code>hypnogram</code> — 1D numpy array of integer stage codes for each 30 s epoch (see <a href="#understanding-results">Sleep Stage Key</a>)</li>
  <li><code>probabilities</code> — 2D array [n_epochs, n_classes] with per-epoch, per-class probabilities</li>
</ul>

<h4>Output files (when enabled)</h4>
<ul>
  <li><code>..._hypnogram.csv</code> — sleep stage code per epoch</li>
  <li><code>..._probabilities.csv</code> — per-epoch class probabilities</li>
  <li><code>..._dashboard.png</code> — plot (if <code>plot=True</code> and file writing enabled)</li>
</ul>

<h4>Parameters (unified catalog)</h4>
<table class="minimal">
  <thead>
    <tr>
      <th style="text-align:left">Parameter</th>
      <th style="text-align:left">Type</th>
      <th style="text-align:left">Default</th>
      <th style="text-align:left">Required when</th>
      <th style="text-align:left">Applies to</th>
      <th style="text-align:left">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>scorer_type</code></td>
      <td><code>str</code></td>
      <td>—</td>
      <td>Always</td>
      <td>PSG | Forehead</td>
      <td><code>'psg'</code> or <code>'forehead'</code>; selects model family and data handling.</td>
    </tr>
    <tr>
      <td><code>output_dir</code></td>
      <td><code>str</code></td>
      <td>—</td>
      <td>Always</td>
      <td>PSG | Forehead</td>
      <td>Directory for outputs. Also used when <code>plot=True</code> to save the dashboard image.</td>
    </tr>
    <tr>
      <td><code>input_file</code></td>
      <td><code>str</code></td>
      <td><em>optional</em></td>
      <td>Required if <code>data</code> is not provided</td>
      <td>PSG | Forehead</td>
      <td>
        Path to input recording file.<br/>
        PSG: EDF/BDF file.<br/>
        Forehead: EDF input. For <code>zmax_mode='two_files'</code>, pass the LEFT or RIGHT channel file; the other file is inferred from the same folder. For <code>zmax_mode='one_file'</code>, both channels are in a single EDF.
      </td>
    </tr>
    <tr>
      <td><code>data</code></td>
      <td><code>numpy.ndarray</code></td>
      <td><em>optional</em></td>
      <td>Required if <code>input_file</code> is not provided</td>
      <td>PSG | Forehead</td>
      <td>
        In-memory signal data.<br/>
        PSG: shape (C, N) — any number of channels C.<br/>
        Forehead: shape (2, N) — exactly 2 channels required.
      </td>
    </tr>
    <tr>
      <td><code>sfreq</code></td>
      <td><code>float</code></td>
      <td><em>optional</em></td>
      <td>Required when using <code>data</code></td>
      <td>PSG | Forehead</td>
      <td>Sampling frequency (Hz) for array input.</td>
    </tr>
    <tr>
      <td><code>ch_names</code></td>
      <td><code>list[str]</code></td>
      <td><em>optional</em></td>
      <td>Optional (array PSG)</td>
      <td>PSG</td>
      <td>Channel names for array input. Auto-generated if omitted.</td>
    </tr>
    <tr>
      <td><code>model_name</code></td>
      <td><code>str</code></td>
      <td>
        PSG: <code>'u-sleep-nsrr-2024_eeg'</code><br/>
        Forehead: <code>'ez6'</code>
      </td>
      <td>Optional</td>
      <td>PSG | Forehead</td>
      <td>
        Selects the model checkpoint to use.<br/>
        PSG: Default is EEG-only weights (<code>..._eeg</code>). If your data includes EOG and you want an EOG-aware model, specify e.g. <code>'u-sleep-nsrr-2024'</code> explicitly.<br/>
        Forehead: Use <code>'ez6'</code> (fast) or <code>'ez6moe'</code> (higher accuracy).
      </td>
    </tr>
    <tr>
      <td><code>device_type</code></td>
      <td><code>str</code></td>
      <td><code>'zmax'</code></td>
      <td>Optional</td>
      <td>Forehead</td>
      <td>Device family selector for forehead data.</td>
    </tr>
    <tr>
      <td><code>zmax_mode</code></td>
      <td><code>str</code></td>
      <td><code>'two_files'</code></td>
      <td>Optional</td>
      <td>Forehead</td>
      <td>
        ZMax input layout.<br/>
        <code>'two_files'</code>: pass LEFT or RIGHT EDF; RIGHT inferred in same folder.<br/>
        <code>'one_file'</code>: both channels in one EDF (optionally set <code>zmax_channels</code>).
      </td>
    </tr>
    <tr>
      <td><code>zmax_channels</code></td>
      <td><code>list[str]</code></td>
      <td><em>optional</em></td>
      <td>Optional; used only with <code>zmax_mode='one_file'</code></td>
      <td>Forehead</td>
      <td>Two channel names to pick from the EDF if using one-file mode. Defaults to the first two channels when omitted.</td>
    </tr>
    <tr>
      <td><code>create_output_files</code></td>
      <td><code>bool | None</code></td>
      <td>
        <code>True</code> when <code>input_file</code> is provided;<br/>
        <code>False</code> when scoring from <code>data</code> (array)
      </td>
      <td>Optional</td>
      <td>PSG | Forehead</td>
      <td>Controls whether CSV/PNG outputs are written to <code>output_dir</code>.</td>
    </tr>
    <tr>
      <td><code>epoch_sec</code></td>
      <td><code>int</code></td>
      <td><code>30</code></td>
      <td>Optional (PSG)</td>
      <td>PSG</td>
      <td>Epoch length in seconds; currently enforced to 30 s in the implementation.</td>
    </tr>
  </tbody>
</table>

<h4>Machine-readable schema</h4>
<pre><code>{
  "entrypoint": "NIDRA.scorer",
  "parameters": {
    "scorer_type": { "type": "string", "enum": ["psg", "forehead"], "required": true },
    "output_dir":  { "type": "string", "required": true },

    "input_file":  { "type": "string", "required_if_absent": "data" },
    "data":        { "type": "array[number]", "shape": "channels x samples", "required_if_absent": "input_file" },
    "sfreq":       { "type": "number", "required_if_present": "data" },

    "ch_names":    { "type": "array[string]", "required": false, "applies": "psg.data" },

    "model_name":  {
      "type": "string",
      "required": false,
      "defaults": { "psg": "u-sleep-nsrr-2024_eeg", "forehead": "ez6" }
    },

    "device_type": { "type": "string", "required": false, "default": "zmax", "applies": "forehead" },
    "zmax_mode":   { "type": "string", "enum": ["two_files","one_file"], "required": false, "default": "two_files", "applies": "forehead" },
    "zmax_channels": { "type": "array[string]", "required": false, "applies": "forehead.zmax_one_file" },

    "create_output_files": {
      "type": "boolean|null",
      "required": false,
      "default_logic": "True if input_file provided, else False"
    },

    "epoch_sec": { "type": "integer", "required": false, "default": 30, "applies": "psg", "enforced": true }
  },

  "returns": {
    "hypnogram": { "type": "array[int]", "epoch_sec": 30 },
    "probabilities": { "type": "array[array[number]]", "shape": "[n_epochs, n_classes]" }
  },

  "artifacts": [
    "hypnogram.csv", "probabilities.csv", "dashboard.png (when plot=True)"
  ]
}</code></pre>

<h4>Minimal requirements by scenario (no examples)</h4>
<ul>
  <li>PSG from file: <code>scorer_type='psg'</code>, <code>input_file</code>, <code>output_dir</code></li>
  <li>PSG from array: <code>scorer_type='psg'</code>, <code>data</code>, <code>sfreq</code>, <code>output_dir</code> (<code>ch_names</code> optional)</li>
  <li>Forehead from file (two-file ZMax): <code>scorer_type='forehead'</code>, <code>input_file</code>, <code>output_dir</code> (<code>zmax_mode</code> defaults to <code>two_files</code>)</li>
  <li>Forehead from file (one-file): <code>scorer_type='forehead'</code>, <code>input_file</code>, <code>output_dir</code>, <code>zmax_mode='one_file'</code> (<code>zmax_channels</code> optional)</li>
  <li>Forehead from array: <code>scorer_type='forehead'</code>, <code>data</code> (2×N), <code>sfreq</code>, <code>output_dir</code></li>
</ul>

<h4>Additional semantics</h4>
<ul>
  <li>Provide exactly one of <code>input_file</code> or (<code>data</code> + <code>sfreq</code>).</li>
  <li>Forehead array input must be exactly two channels (2×N).</li>
  <li>ZMax two-file mode: pass the LEFT or RIGHT channel EDF; the other will be inferred in the same folder via L/R naming.</li>
  <li>ZMax one-file mode: optionally specify <code>zmax_channels</code>; otherwise the first two channels are used.</li>
  <li>PSG array accepts any channel count; <code>ch_names</code> optional and auto-generated if omitted.</li>
  <li>PSG default model is EEG-only (<code>..._eeg</code>). Specify a non-EEG-only name (e.g. <code>u-sleep-nsrr-2024</code>) for EOG-aware inference.</li>
  <li>All models operate on 30-second epochs; outputs align to full epochs.</li>
</ul>

<h4>Batch processing</h4>
<p>
  For processing a study directory, use <code>NIDRA.batch_scorer(input_dir=..., output=..., type=..., model=None, dir_list=None, channels=None, probabilities=False, plot=False)</code>, then call <code>.score(gen_stats=True)</code>. This discovers valid recordings under <code>input_dir</code> and writes results into a timestamped folder in <code>output_dir</code>. Returns <code>(processed_count, total_found)</code>.
</p>

</section>

        <section id="how-to-cite">
            <h2>How to cite NIDRA</h2>
            <p>If you use NIDRA in your research, please cite both the NIDRA software itself and the paper for the specific model you used.</p>
            <h3>1. Citing the NIDRA Software</h3>
            <p>Please cite this repository to ensure reproducibility:</p>
            <pre>
Zerr, P. (2025). NIDRA: super simple sleep scoring. GitHub. https://github.com/paulzerr/nidra
</pre>
            <h3>2. Citing the Scoring Model</h3>
            <p><strong>If you used the ez6 or ez6moe models:</strong></p>
            <pre>
Coon WG, Zerr P, Milsap G, et al. (2025). "ezscore-f: A Set of Freely Available, Validated Sleep Stage Classifiers for Forehead EEG." bioRxiv. doi: 10.1101/2025.06.02.657451.
</pre>
            <p><strong>If you used the u-sleep-nsrr-2024 model:</strong></p>
            <p>Please cite the original U-Sleep paper and the SLEEPYLAND paper for the re-trained model weights:</p>
            <pre>
Perslev, M., et al. (2021). "U-Sleep: resilient high-frequency sleep staging." NPJ digital medicine.
Rossi, A. D., et al. (2025). "SLEEPYLAND: trust begins with fair evaluation of automatic sleep staging models." arXiv preprint.
</pre>
        </section>

        <section id="faq">
            <h2>FAQ & troubleshooting</h2>
            <h3>Installation issues</h3>
            <p><strong>Q: I'm having trouble installing with pip. What can I do?</strong><br>
            A: Installation problems can be frustrating, but they are often solvable. Here are a few common troubleshooting steps:
            <ul>
                <li><strong>1. Update Core Packages:</strong> Ensure you have the latest versions of pip, setuptools, and wheel, as outdated versions can cause issues. You can update them by running:
                    <pre><code>pip install --upgrade pip setuptools wheel</code></pre>
                </li>
                <li><strong>2. Use a Clean Virtual Environment:</strong> Conflicts with other installed packages are a common source of errors. Creating a fresh virtual environment ensures that NIDRA's dependencies are installed in an isolated space. If you are still having issues, try creating a new environment from scratch.</li>
                <li><strong>3. Try Installing with Conda:</strong> If pip continues to fail, installing NIDRA via a Conda environment can be a more reliable alternative. Conda's package management is often better at resolving complex dependencies. Follow the Conda installation instructions in the <a href="#installation">Installation</a> section.</li>
            </ul></p>
            <h3>GUI issues</h3>
            <p><strong>Q: The GUI window is not appearing when I run <code>nidra</code>.</strong><br>
            A: Check the terminal for any error messages. This could be due to a missing dependency. Try reinstalling NIDRA in a clean virtual environment.</p>
            <p><strong>Q: Why is the "Run" button greyed out?</strong><br>
            A: The "Run" button is disabled until you have selected a valid Input Directory.</p>
            <h3>Scoring errors</h3>
            <p><strong>Q: I got an error about "missing channels" or "could not find required channels".</strong><br>
            A: This is a common error that occurs when the channel labels in your EDF file do not match what the model expects, or when you've selected the wrong "Data Source". For example, selecting "PSG" for a forehead EEG file will cause this error. Double-check your data source selection and ensure your EDF channel labels are standard.</p>
            <p><strong>Q: The scoring process is very slow.</strong><br>
            A: Sleep scoring is computationally intensive, but a typical overnight recording should take less than a minute on modern hardware. If it is taking much longer, ensure no other resource-heavy processes are running on your computer.</p>
            <h3>General questions</h3>
            <p><strong>Q: Can I trust the results?</strong><br>
            A: The models in NIDRA are validated and perform at a level comparable to human experts. However, like any automated algorithm, they are not perfect. It is always good practice to visually inspect the generated hypnogram plot for any obvious anomalies, especially for noisy or unusual recordings.</p>
        </section>

        <section id="attribution">
            <h2>Attribution</h2>
            <p>ez6 and ez6moe models were developed by Coon et al., see:
            <br>Coon WG, Zerr P, Milsap G, Sikder N, Smith M, Dresler M, Reid M.
            <br>"ezscore-f: A Set of Freely Available, Validated Sleep Stage Classifiers for Forehead EEG."
            <br><a href="https://www.biorxiv.org/content/10.1101/2025.06.02.657451v1">https://www.biorxiv.org/content/10.1101/2025.06.02.657451v1</a>
            <br><a href="https://github.com/coonwg1/ezscore">github.com/coonwg1/ezscore</a></p>

            <p>U-Sleep models were developed by  Perslev et al., see:
            <br>Perslev, M., Darkner, S., Kempfner, L., Nikolic, M., Jennum, P. J., & Igel, C. (2021).
            <br>U-Sleep: resilient high-frequency sleep staging. NPJ digital medicine
            <br><a href="https://www.nature.com/articles/s41746-021-00440-5">https://www.nature.com/articles/s41746-021-00440-5</a>
            <br><a href="https://github.com/perslev/U-Time">https://github.com/perslev/U-Time</a></p>

            <p>The U-Sleep model weights used in this repo were re-trained by Rossi et al., see:
            <br>Rossi, A. D., Metaldi, M., Bechny, M., Filchenko, I., van der Meer, J., Schmidt, M. H., ... & Fiorillo, L. (2025).
            <br>SLEEPYLAND: trust begins with fair evaluation of automatic sleep staging models. arXiv preprint arXiv:2506.08574.
            <br><a href="https://arxiv.org/abs/2506.08574v1">https://arxiv.org/abs/2506.08574v1</a></p>
        </section>

        <section id="license">
            <h2>License</h2>
            <p>This project is licensed under the MIT License. See the LICENSE file for details.</p>
        </section>

        <section id="contact">
            <h2>Contact</h2>
            <p>For questions, bug reports, or feedback, please contact Paul Zerr at <a href="mailto:zerr.paul@gmail.com">zerr.paul@gmail.com</a> or open a github issue.</p>
        </section>

    </main>
</body>
</html>
