<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NIDRA</title>
    <link rel="stylesheet" href="style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
</head>
<body>
    <nav class="sidebar">
        <div class="sidebar-header">
            <img src="logo.png" alt="NIDRA Logo" class="sidebar-logo">
        </div>
        <ul>
            <li><a href="#introduction">Introduction</a></li>
            <li><a href="#installation">Installation</a></li>
            <li><a href="#gui-guide">GUI (Overview)</a></li>
            <li><a href="#preparing-data">Preparing Your Data</a></li>
            <li><a href="#gui-walkthrough">GUI (Walkthrough)</a></li>
            <li><a href="#model-performance">Model Validation</a></li>
            <li><a href="#understanding-results">Understanding Results</a></li>
            <li><a href="#cli-guide">CLI Guide</a></li>
            <li><a href="#python-package">Python Guide</a></li>
            <li><a href="#install-from-source">Install from Source</a></li>
            <li><a href="#how-to-cite">How to Cite</a></li>
            <li><a href="#faq">FAQ & Troubleshooting</a></li>
            <li><a href="#attribution">Attribution</a></li>
            <li><a href="#license">License</a></li>
            <li><a href="#contact">Contact</a></li>
        </ul>
    </nav>
    <main class="content">
        <section id="introduction">
            <h2>NIDRA v0.1 - super simple sleep scoring</h2>
            <p>Neural networks can perform highly accurate, automated sleep scoring, but these technologies are often difficult to implement.</p>
            <p>NIDRA is a fool-proof, simple-to-use tool for scoring sleep recordings using the best currently available autoscoring machine learning algorithms. No programming required, but a CLI and python endpoints are available.</p>
            <p>NIDRA can autoscore data from polysomnography (PSG) recordings, as well as from 2-channel EEG wearables (such as ZMax).</p>
            <p>NIDRA enables anyone, including researchers without any programming experience, to use cutting-edge sleep scoring models.</p>
            <p>NIDRA uses the highly accurate U-Sleep2.0 and ez6moe models by default. Both models have been validated (see below) and perform sleep scoring on the level of human interrater agreement.</p>
        </section>

        <section id="installation">
            <h2>Installation</h2>
            <h4>Option 1: Standalone Executable (Recommended for non-technical users)</h4>
            <p>The easiest way to use NIDRA on Windows is via the portable, ready-to-go executables which require no installation. Simply download the correct version for your operating system and run it.</p>
            <ul>
                <h3><strong><a href="LINK">Download standalone exe for Windows 10+</a></strong></h3>
                <br>
            </ul>
            <p><strong>Note:</strong> due to the restrictive environment of Windows, you may see a "Search on app store" popup window. Click "No". You may also see the blue Smartscreen warning. In that case click "run anyway". Should this fail, try installing via pip (see below).</p>
            <br>
            <h4>Option 2: Install from PyPI</h4>
            <p>First, make sure you have Python installed (3.10 or later recommended). We suggest installing via <a href="https://www.anaconda.com/download/success">Miniconda</a>.</p>
            <p>Before installing NIDRA, it is highly recommended to create and activate a new virtual environment. This prevents conflicts with other packages.</p>
            <p><strong>To create a virtual environment (choose one):</strong></p>
            <p>1. Using <code>venv</code> (built-in):</p>
            <pre><code># Create the environment
python3 -m venv nidra-env
# Activate it
# On Windows:
nidra-env\Scripts\activate
# On macOS/Linux:
source nidra-env/bin/activate</code></pre>
            <p>2. Using <code>conda</code>:</p>
            <pre><code># Create and activate the environment
conda create -n nidra-env python=3.10
conda activate nidra-env</code></pre>
            <p>Once your environment is activated, install NIDRA using pip:</p>
            <pre><code>pip install nidra</code></pre>
            <p>Once installed, you can launch the graphical interface by running the command: </p>
            <pre><code>nidra</code></pre>
            <p><strong>Note:</strong> If you installed NIDRA via pip, the first time you run a scoring process, the necessary model files will be automatically downloaded from <a href="https://huggingface.co/pzerr/NIDRA_models/">https://huggingface.co/pzerr/NIDRA_models/</a> (~152MB). </p>
            <br>
            <h4>Option 3: Install from source</h4>
            <p><strong>macOS and Linux:</strong></p>
            <pre><code>git clone https://codeberg.org/pzerr/NIDRA.git
cd NIDRA
python3 -m venv .venv
source .venv/bin/activate
pip install .</code></pre>
            <p><strong>Windows:</strong></p>
            <pre><code>git clone https://codeberg.org/pzerr/NIDRA.git
cd NIDRA
python -m venv .venv
.venv\Scripts\activate
pip install .</code></pre>
        </section>

        <section id="gui-guide">
            <h2>Graphical User Interface (GUI)</h2>
            <p>The GUI provides an intuitive, point-and-click way to score sleep recordings. The easiest way to launch the GUI is by running the standalone executable. If you installed NIDRA as a package, you can launch it by opening your terminal and running the command: <code>nidra</code></p>
            <img src="gui.png" alt="Screenshot of the NIDRA GUI" style="width: 100%; max-width: 960px; display: block; margin: 20px 0;">
            <p><b>Fig.1</b> - Screenshot of the GUI</p>
            <h3>Quick Guide</h3>
            <ol>
                <li><strong>Input Folder</strong>: Select the directory containing the sleep recording data.</li>
                <li><strong>Output Folder</strong>: Select the directory where the results will be saved.</li>
                <li><strong>Scoring Mode</strong>: Choose to score a single recording or batch-process all subdirectories, eaching containing one recording.</li>
                <li><strong>Data Source</strong>: Select "Forehead EEG" or "PSG".</li>
                <li><strong>Model</strong>: Select the appropriate model for your data source. Default models are reliable.</li>
                <li><strong>Options</strong>: Choose whether to generate plots and statistics.</li>
                <li><strong>Run</strong>: Start the scoring process.</li>
            </ol>
            <p>A more detailed walkthrough is provided in the sections below.</p>
        </section>

        <section id="preparing-data">
            <h2>Preparing Your Data</h2>
            <p>For NIDRA to process your recordings correctly, your files and folders must be organized in a specific way. Please follow these guidelines to avoid errors.</p>
            <h3>General Requirements</h3>
            <ul>
                <li><strong>File Format:</strong> NIDRA exclusively works with European Data Format (.edf) files.</li>
                <li><strong>Channel Labels:</strong> Ensure your EDF files have standard channel labels (e.g., 'EEG Fpz-Cz', 'EOG left', 'Fp1', 'O2-M1') for PSG data, as NIDRA uses these to identify channel types.</li>
            </ul>
            <h3>Data Structure Guide</h3>
            <p>Whether you are scoring a single file or batch processing, NIDRA expects each recording session to be in its own folder. When using the "Score all subdirectories" mode, NIDRA will treat every subfolder in your input directory as a separate recording.</p>
            <p><strong>Structure for Forehead EEG (e.g., ZMax):</strong></p>
            <p>For two-channel forehead EEG data, the left and right channel files must be in the same directory. For ZMax data, these are typically named <code>EEG_L.edf</code> and <code>EEG_R.edf</code>.</p>
            <pre>
forehead_study/
├── subject_01/
|   ├── EEG_L.edf
|   └── EEG_R.edf
├── subject_02/
|   ├── night01_L.edf
|   └── night01_R.edf
</pre>
            <p><strong>Structure for PSG:</strong></p>
            <p>For PSG data, each EDF file should be in its own directory. NIDRA can process multiple recordings in subdirectories, as shown in this example with three recordings:</p>
            <pre>
psg_study/
├── subject_02/
|   └── night_recording_1.edf
├── subject_03/
|   └── night_recording_2.edf
└── subject_04/
    └── another_night.edf
</pre>
        </section>

        <section id="gui-walkthrough">
            <h2>GUI Guide: A Step-by-Step Walkthrough</h2>
            <p>This guide provides a detailed walkthrough of how to score a sleep recording using the NIDRA graphical interface, from launching the application to interpreting your results.</p>
            <h3>Step 1: Launching the Application</h3>
            <p>The easiest way is to double-click the standalone executable file you downloaded. Alternatively, if you installed NIDRA as a package, open your terminal and type <code>nidra</code>, then press Enter. The main application window will appear.</p>
            <h3>Step 2: Setting Input and Output Paths</h3>
            <p>Your first step is to tell NIDRA where your data is and where the results should go.</p>
            <ul>
                <li><strong>Input Directory:</strong> Click the "Browse files..." button. A file dialog will open. Navigate to and select the folder that contains your sleep recording file(s). For batch processing, this would be your main project folder containing subdirectories for each subject.</li>
                <li><strong>Output Directory:</strong> Specify the folder where NIDRA will save the scoring results. If you leave this blank, NIDRA will automatically create a new folder named <code>autoscorer_output</code> inside your input directory. This is the recommended approach for keeping your data and results organized.</li>
            </ul>
            <h3>Step 3: Configuring the Scoring Mode</h3>
            <p>NIDRA offers two modes for processing:</p>
            <ul>
                <li><strong>Score single recording:</strong> Choose this if the folder you selected as your input contains the files for only one sleep session.</li>
                <li><strong>Score all recordings (in subfolders):</strong> Choose this for batch processing. NIDRA will look for subdirectories within your selected input folder and process each one as a separate recording.</li>
            </ul>
            <h3>Step 4: Selecting the Data Source and Model</h3>
            <p>This is a critical step to ensure high-quality scoring.</p>
            <ul>
                <li><strong>Data Source:</strong> Select the type of recording you have. Choose "Forehead EEG" for 2-channel wearable data or "PSG" for standard polysomnography data.</li>
                <li><strong>Model:</strong> The available models will change based on your data source. For forehead EEG, <code>ez6moe</code> is recommended for its high accuracy. For PSG, <code>u-sleep-nsrr-2024</code> is the standard choice.</li>
            </ul>
            <h3>Step 5: Running the Analysis and Monitoring Progress</h3>
            <p>Before starting, you can choose to generate plots and sleep statistics using the checkboxes. It is highly recommended to keep these enabled. Click the <strong>"Run NIDRA autoscoring"</strong> button to begin. The button will be disabled and read "Running..." during processing. You can monitor the real-time progress in the console panel on the right. This log will show which files are being processed and report any warnings or errors.</p>
        </section>

        <section id="model-performance">
            <h2>Model Validation and Performance</h2>
            <p>The models included in NIDRA have been rigorously validated against manually scored data from human experts. Below is a summary of their performance.</p>
            <h3>ez6 and ez6moe for Forehead EEG</h3>
            <p>The <code>ez6moe</code> model was validated against expert-scored PSG recordings. The confusion matrix below shows the model's predictions (y-axis) versus the expert labels (x-axis). The diagonal represents correct classifications. As you can see, the model shows high agreement with the expert scorer, particularly for Wake, N2, and REM sleep.</p>
            <img src="matrix.png" alt="Confusion matrix of the ez6moe model" style="width: 60%; max-width: 600px; display: block; margin: 20px 0;">
            <p><b>Fig.2</b> - Confusion matrix (vs. manually scored PSG) of the artefact-aware ez6moe model.</p>
            <p>Key performance metrics, such as accuracy and Cohen's Kappa (a measure of inter-rater agreement), are comparable to the agreement levels seen between different human experts. For full details, please refer to the original publication.</p>
            <h3>U-Sleep for PSG</h3>
            <p>The U-Sleep model is a well-established, state-of-the-art algorithm for PSG sleep scoring. The version used in NIDRA (<code>u-sleep-nsrr-2024</code>) is a robust implementation trained on a large dataset. It demonstrates high performance across diverse populations and recording conditions. For detailed performance metrics, please see the original U-Sleep and SLEEPYLAND publications linked in the Attribution section.</p>
        </section>

        <section id="understanding-results">
            <h2>Understanding Your Results</h2>
            <p>Once NIDRA has finished processing, you will find several output files in your specified output directory. Here's what they are and how to use them.</p>
            <h3>The Output Files</h3>
            <p>For each recording, NIDRA generates up to four files:</p>
            <ul>
                <li><strong>Hypnogram File (<code>..._hypnogram.csv</code>):</strong> This is the main output. It's a CSV file with a single column of numbers, where each number is the sleep stage for one 30-second epoch.</li>
                <li><strong>Probabilities File (<code>..._probabilities.csv</code>):</strong> This file contains the raw probabilities for each sleep stage for every epoch. Each row corresponds to an epoch, and each column corresponds to a sleep stage (Wake, N1, N2, N3, REM, Artifact). This is useful for advanced analysis of model confidence.</li>
                <li><strong>Dashboard Plot (<code>..._dashboard.png</code>):</strong> An image that visualizes the hypnogram and underlying data, showing the progression of sleep stages over the night.</li>
                <li><strong>Sleep Statistics (<code>..._sleep_statistics.csv</code>):</strong> A CSV file with a detailed summary of sleep metrics like Total Sleep Time, Sleep Efficiency, and time spent in each stage.</li>
            </ul>
            
            <h3>Sleep Stage Key</h3>
            <p>The hypnogram uses the following standard numeric codes for sleep stages:</p>
            <ul>
                <li><strong>0:</strong> Wake</li>
                <li><strong>1:</strong> NREM1</li>
                <li><strong>2:</strong> NREM2</li>
                <li><strong>3:</strong> NREM3</li>
                <li><strong>5:</strong> REM</li>
                <li><strong>6:</strong> Artifact</li>
            </ul>
        </section>

        <section id="cli-guide">
            <h2>CLI Guide: Automating Scoring</h2>
            <p>The Command-Line Interface (CLI) is a powerful feature for processing large datasets and integrating NIDRA into automated workflows.</p>
            <h3>Basic Command Structure</h3>
            <p>The fundamental command is <code>nidra score</code>. You must provide the input path, output directory, and the type of scorer.</p>
            <pre><code>nidra score --input_path /path/to/data --output_dir /path/to/output --scorer_type forehead</code></pre>
            <h3>Example: Batch Processing a Full Study</h3>
            <p>Let's say you have a study with data structured as recommended in the "Preparing Your Data" section. You can process all subjects with a single command by pointing the <code>--input_path</code> to the main study directory.</p>
            <pre><code>nidra score --input_path /my_study_data/ --output_dir /my_study_results/ --scorer_type forehead --model_name ez6moe</code></pre>
            <p>NIDRA will automatically find the subdirectories (subject_01, subject_02, etc.), process each one, and place the results in a correspondingly named folder inside <code>/my_study_results/</code>.</p>
        </section>

        <section id="python-package">
            <h2>Python Package: Advanced Integration</h2>
            <p>Using NIDRA as a Python package provides the ultimate flexibility, allowing you to integrate automated scoring directly into your data analysis pipelines.</p>
            <h3>Core Concept: The Scorer Factory</h3>
            <p>The main entry point is the <code>NIDRA.scorer()</code> factory function. You call this function to create a scorer instance, providing it with the configuration for your scoring task. Then, you call the <code>.score()</code> method on the returned object to run the analysis.</p>
            
            <h4><code>NIDRA.scorer(...)</code> Parameters</h4>
            <p>When creating a scorer, you must provide the following arguments:</p>
            <ul>
                <li><code>scorer_type</code> (str): The type of data. Must be either <code>'forehead'</code> or <code>'psg'</code>.</li>
                <li><code>output_dir</code> (str): The path to the directory where results will be saved.</li>
                <li><code>input_file</code> (str, optional): The full path to the input EDF file. Required if not providing data as a NumPy array.</li>
                <li><code>data</code> (np.ndarray, optional): An in-memory NumPy array of the EEG/PSG data. If you use this, <code>input_file</code> should be <code>None</code>.</li>
                <li><code>model_name</code> (str, optional): The name of the model to use. If not provided, a default model will be selected.</li>
                <li><strong>For PSG data from NumPy array:</strong>
                    <ul>
                        <li><code>sfreq</code> (float): The sampling frequency of the data.</li>
                        <li><code>ch_names</code> (list of str): A list of channel names.</li>
                    </ul>
                </li>
            </ul>

            <h4><code>scorer.score(...)</code> Method</h4>
            <p>This method runs the scoring process. It takes one optional argument:</p>
            <ul>
                <li><code>plot</code> (bool, optional): If <code>True</code>, a dashboard plot will be generated. Defaults to <code>False</code>.</li>
            </ul>
            <p><strong>Returns:</strong></p>
            <p>The method returns a tuple containing two NumPy arrays:</p>
            <ol>
                <li><strong>hypnogram</strong> (<code>numpy.ndarray</code>): A 1D array of integers representing the sleep stage for each 30-second epoch. See the <a href="#understanding-results">Sleep Stage Key</a> for the meaning of each integer.</li>
                <li><strong>probabilities</strong> (<code>numpy.ndarray</code>): A 2D array of shape (n_epochs, n_classes). Each row corresponds to an epoch, and each column contains the model's predicted probability for a specific sleep stage.</li>
            </ol>

            <h3>Example 1: Scoring a PSG File</h3>
            <p>This example shows how to score a single PSG recording from an EDF file.</p>
            <pre>
import NIDRA

# Initialize the scorer
scorer = NIDRA.scorer(
    scorer_type='psg',
    input_file='/path/to/your/data/sleep_recording.edf',
    output_dir='/path/to/your/output',
    model_name='u-sleep-nsrr-2024'
)

# Run scoring
hypnogram, probabilities = scorer.score(plot=True)

print("Scoring complete.")
print("Hypnogram shape:", hypnogram.shape)
print("Probabilities shape:", probabilities.shape)
</pre>

            <h3>Example 2: Scoring In-Memory NumPy Data</h3>
            <p>You can also score data that you already have in memory as a NumPy array, bypassing the need for file I/O. This is useful for real-time applications or custom data loading pipelines. When scoring PSG data from an array, you must provide the sampling frequency (<code>sfreq</code>). Providing channel names is recommended but optional; if not provided, they will be auto-generated.</p>
            <pre>
import NIDRA
import numpy as np

# --- Create some dummy PSG data ---
sfreq = 256
ch_names = ['F3-A2', 'C4-A1', 'O2-A1', 'EOG-L']
n_samples = sfreq * 60 * 60  # 1 hour of data
dummy_data = np.random.randn(len(ch_names), n_samples)

# --- Initialize and run the scorer ---
scorer = NIDRA.scorer(
    scorer_type='psg',
    output_dir='/path/to/numpy_psg_output',
    data=dummy_data,
    sfreq=sfreq,
    ch_names=ch_names  # This parameter is optional
)
hypnogram, probabilities = scorer.score()
</pre>
            <h3>Example 3: Batch Processing a Study</h3>
            <p>For batch processing, NIDRA provides a convenient <code>batch_scorer</code>. This function automatically discovers all valid recordings in the subdirectories of your input path, mirroring the behavior of the GUI. This is the recommended way to process a full study. Please see the <a href="#preparing-data">Preparing Your Data</a> section for details on how to structure your study directory.</p>
            <pre>
import NIDRA

# --- 1. Initialize the batch scorer ---
# Provide the path to your main study directory and where the results should go.
batch = NIDRA.batch_scorer(
    input_dir='/path/to/your/study_data',
    output_dir='/path/to/your/study_output',
    scorer_type='forehead',  # or 'psg'
    model_name='ez6moe'
)

# --- 2. Run the scoring process ---
# This will find and score all recordings.
# The results for each recording will be saved in a subfolder within a timestamped batch_run_* directory.
processed_count, total_found = batch.score(plot=True, gen_stats=True)

print(f"Batch processing complete. Successfully scored {processed_count} out of {total_found} recordings.")
</pre>
            <p>This simplified approach removes the need to manually loop through directories and handle file paths, making your analysis scripts cleaner and more reliable.</p>
        </section>

        <section id="install-from-source">
            <h2>Install from Source Code</h2>
            <p>For developers or users who need the latest (potentially unstable) version, NIDRA can be installed by cloning the git repository:</p>
            <ol>
                <li><strong>Clone the repository:</strong>
                    <pre><code>git clone https://codeberg.org/pzerr/NIDRA.git
cd NIDRA</code></pre>
                </li>
                <li><strong>Create and activate a virtual environment:</strong>
                    <p>On macOS and Linux:</p>
                    <pre><code>python3 -m venv .venv
source .venv/bin/activate</code></pre>
                    <p>On Windows:</p>
                    <pre><code>python -m venv .venv
.venv\Scripts\activate</code></pre>
                </li>
                <li><strong>Install the package:</strong>
                    <pre><code>pip install .</code></pre>
                </li>
            </ol>
            <h4>(Optional) Building the Executable</h4>
            <p>After installing from source, you can also build the standalone executable yourself. This is useful for distributing your own modified version of NIDRA.</p>
            <p>The repository includes build scripts for each operating system located in the <code>setup/</code> directory.</p>
            <ol>
                <li><strong>Navigate to the setup directory:</strong>
                    <pre><code>cd setup</code></pre>
                </li>
                <li><strong>Run the build script for your OS:</strong>
                    <p>On macOS and Linux:</p>
                    <pre><code>./build.sh</code></pre>
                    <p>On Windows:</p>
                    <pre><code>build.bat</code></pre>
                </li>
                <li><strong>Find the executable:</strong>
                    <p>Once the script finishes, the final executable will be located in the <code>dist</code> directory at the root of the project.</p>
                </li>
            </ol>
        </section>

        <section id="how-to-cite">
            <h2>How to Cite NIDRA</h2>
            <p>If you use NIDRA in your research, please cite both the NIDRA software itself and the paper for the specific model you used.</p>
            <h3>1. Citing the NIDRA Software</h3>
            <p>Please cite this repository to ensure reproducibility:</p>
            <pre>
Zerr, P. (2025). NIDRA: Neural Inferencer for Deep Rest Analysis. Codeberg. https://codeberg.org/pzerr/NIDRA
</pre>
            <h3>2. Citing the Scoring Model</h3>
            <p><strong>If you used the ez6 or ez6moe models:</strong></p>
            <pre>
Coon WG, Zerr P, Milsap G, et al. (2025). "ezscore-f: A Set of Freely Available, Validated Sleep Stage Classifiers for Forehead EEG." bioRxiv. doi: 10.1101/2025.06.02.657451.
</pre>
            <p><strong>If you used the u-sleep-nsrr-2024 model:</strong></p>
            <p>Please cite the original U-Sleep paper and the SLEEPYLAND paper for the re-trained model weights:</p>
            <pre>
Perslev, M., et al. (2021). "U-Sleep: resilient high-frequency sleep staging." NPJ digital medicine.
Rossi, A. D., et al. (2025). "SLEEPYLAND: trust begins with fair evaluation of automatic sleep staging models." arXiv preprint.
</pre>
        </section>

        <section id="faq">
            <h2>FAQ & Troubleshooting</h2>
            <h3>Installation Issues</h3>
            <p><strong>Q: I'm having trouble installing with pip. What can I do?</strong><br>
            A: Ensure you are using a recent version of Python (3.10+) and pip. It is highly recommended to install NIDRA in a virtual environment to avoid conflicts. Try running <code>pip install --upgrade pip</code> before installing NIDRA.</p>
            <h3>GUI Issues</h3>
            <p><strong>Q: The GUI window is not appearing when I run <code>nidra</code>.</strong><br>
            A: Check the terminal for any error messages. This could be due to a missing dependency. Try reinstalling NIDRA in a clean virtual environment.</p>
            <p><strong>Q: Why is the "Run" button greyed out?</strong><br>
            A: The "Run" button is disabled until you have selected a valid Input Directory.</p>
            <h3>Scoring Errors</h3>
            <p><strong>Q: I got an error about "missing channels" or "could not find required channels".</strong><br>
            A: This is a common error that occurs when the channel labels in your EDF file do not match what the model expects, or when you've selected the wrong "Data Source". For example, selecting "PSG" for a forehead EEG file will cause this error. Double-check your data source selection and ensure your EDF channel labels are standard.</p>
            <p><strong>Q: The scoring process is very slow.</strong><br>
            A: Sleep scoring is computationally intensive, but a typical overnight recording should take less than a minute on modern hardware. If it is taking much longer, ensure no other resource-heavy processes are running on your computer.</p>
            <h3>General Questions</h3>
            <p><strong>Q: Can I trust the results?</strong><br>
            A: The models in NIDRA are validated and perform at a level comparable to human experts. However, like any automated algorithm, they are not perfect. It is always good practice to visually inspect the generated hypnogram plot for any obvious anomalies, especially for noisy or unusual recordings.</p>
        </section>

        <section id="attribution">
            <h2>Attribution</h2>
            <p>ez6 and ez6moe models were developed by Coon et al., see:
            <br>Coon WG, Zerr P, Milsap G, Sikder N, Smith M, Dresler M, Reid M.
            <br>"ezscore-f: A Set of Freely Available, Validated Sleep Stage Classifiers for Forehead EEG."
            <br><a href="https://www.biorxiv.org/content/10.1101/2025.06.02.657451v1">https://www.biorxiv.org/content/10.1101/2025.06.02.657451v1</a>
            <br><a href="https://github.com/coonwg1/ezscore">github.com/coonwg1/ezscore</a></p>
            
            <p>U-Sleep models were developed by  Perslev et al., see:
            <br>Perslev, M., Darkner, S., Kempfner, L., Nikolic, M., Jennum, P. J., & Igel, C. (2021).
            <br>U-Sleep: resilient high-frequency sleep staging. NPJ digital medicine
            <br><a href="https://www.nature.com/articles/s41746-021-00440-5">https://www.nature.com/articles/s41746-021-00440-5</a>
            <br><a href="https://github.com/perslev/U-Time">https://github.com/perslev/U-Time</a></p>

            <p>The U-Sleep model weights used in this repo were re-trained by Rossi et al., see:
            <br>Rossi, A. D., Metaldi, M., Bechny, M., Filchenko, I., van der Meer, J., Schmidt, M. H., ... & Fiorillo, L. (2025).
            <br>SLEEPYLAND: trust begins with fair evaluation of automatic sleep staging models. arXiv preprint arXiv:2506.08574.
            <br><a href="https://arxiv.org/abs/2506.08574v1">https://arxiv.org/abs/2506.08574v1</a></p>
        </section>

        <section id="license">
            <h2>License</h2>
            <p>This project is licensed under the MIT License. See the LICENSE file for details.</p>
        </section>

        <section id="contact">
            <h2>Contact</h2>
            <p>For questions, bug reports, or feedback, please contact Paul Zerr at <a href="mailto:zerr.paul@gmail.com">zerr.paul@gmail.com</a>.</p>
        </section>

    </main>
</body>
</html>
